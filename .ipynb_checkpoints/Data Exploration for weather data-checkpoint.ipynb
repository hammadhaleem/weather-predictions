{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_airquality = pd.DataFrame.from_csv('data/airquality.csv')\n",
    "df_district = pd.DataFrame.from_csv('data/district.csv')\n",
    "df_meteorology = pd.DataFrame.from_csv('data/meteorology.csv')\n",
    "df_station = pd.DataFrame.from_csv('data/station.csv')\n",
    "df_weatherforecast = pd.DataFrame.from_csv('data/weatherforecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df = df_airquality.join(df_station)\n",
    "final_df = final_df.reset_index()\n",
    "final_df['station_id'] = final_df['\\ufeffstation_id']\n",
    "final_df = final_df.drop('\\ufeffstation_id',1)\n",
    "final_df = final_df.join(df_district, on=['district_id'],rsuffix='_district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_city = pd.DataFrame.from_csv('data/city.csv')\n",
    "df_city = df_city.reset_index()\n",
    "\n",
    "df_city['city_id'] = df_city['\\ufeffcity_id']\n",
    "df_city['latitude_city']= df_city['longitude']\n",
    "df_city['longitude_city']= df_city['longitude']\n",
    "\n",
    "df_city = df_city.drop('latitude',1)\n",
    "df_city = df_city.drop('longitude',1)\n",
    "\n",
    "df_city = df_city.drop('\\ufeffcity_id',1)\n",
    "df_city['city_id'] = df_city.city_id.apply(lambda x : int(x))\n",
    "final_df = pd.merge(final_df, right=df_city,on=['city_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('name_chinese_x',1)\n",
    "final_df = final_df.drop('name_chinese_district',1)\n",
    "final_df = final_df.drop('name_chinese_y',1)\n",
    "final_df = final_df.drop('name_english_y',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology = df_meteorology.reset_index()\n",
    "df_meteorology['id'] = df_meteorology['\\ufeffid']\n",
    "df_meteorology = df_meteorology.drop('\\ufeffid',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology['district_id'] = df_meteorology['id']\n",
    "df_meteorology = df_meteorology.drop('id',1)\n",
    "final_df = pd.merge(final_df, right=df_meteorology,on=['district_id','time'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['latitude_city']  = final_df['latitude_city'].apply(lambda x : str(x))\n",
    "final_df['longitude_city']  = final_df['longitude_city'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['latitude']  = final_df['latitude'].apply(lambda x : str(x))\n",
    "final_df['longitude']  = final_df['longitude'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['lat-lon-city'] = final_df['latitude_city'] + ' ' + final_df['longitude_city']\n",
    "final_df['lat-lon-district'] = final_df['latitude'] + ' ' + final_df['longitude']\n",
    "\n",
    "final_df = final_df.drop('latitude_city',1)\n",
    "final_df = final_df.drop('longitude_city',1)\n",
    "\n",
    "final_df = final_df.drop('latitude',1)\n",
    "final_df = final_df.drop('longitude',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['time'] = final_df.time.apply(lambda x : datetime.datetime.strptime(str(x),'%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "final_df['year']    = final_df['time'].apply(lambda x : x.year)\n",
    "final_df['month']   = final_df['time'].apply(lambda x : x.month)\n",
    "final_df['day']     = final_df['time'].apply(lambda x : x.day)\n",
    "final_df['hour']    = final_df['time'].apply(lambda x : x.hour)\n",
    "\n",
    "final_df = final_df.drop('time',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3923229 entries, 0 to 3923228\n",
      "Data columns (total 24 columns):\n",
      "PM25_Concentration       float64\n",
      "PM10_Concentration       float64\n",
      "NO2_Concentration        float64\n",
      "CO_Concentration         float64\n",
      "O3_Concentration         float64\n",
      "SO2_Concentration        float64\n",
      "name_english_x           object\n",
      "district_id              float64\n",
      "station_id               float64\n",
      "name_english_district    object\n",
      "city_id                  float64\n",
      "cluster_id               float64\n",
      "weather                  float64\n",
      "temperature              float64\n",
      "pressure                 float64\n",
      "humidity                 float64\n",
      "wind_speed               float64\n",
      "wind_direction           float64\n",
      "lat-lon-city             object\n",
      "lat-lon-district         object\n",
      "year                     int64\n",
      "month                    int64\n",
      "day                      int64\n",
      "hour                     int64\n",
      "dtypes: float64(16), int64(4), object(4)\n",
      "memory usage: 748.3+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it to a temporary data frame \n",
    "final_df.to_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hammadhaleem/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame.from_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PM25_Concentration', 'PM10_Concentration', 'NO2_Concentration',\n",
       "       'CO_Concentration', 'O3_Concentration', 'SO2_Concentration',\n",
       "       'name_english_x', 'district_id', 'station_id', 'name_english_district',\n",
       "       'city_id', 'cluster_id', 'weather', 'temperature', 'pressure',\n",
       "       'humidity', 'wind_speed', 'wind_direction', 'lat-lon-city',\n",
       "       'lat-lon-district', 'year', 'month', 'day', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "      <th>name_english_x</th>\n",
       "      <th>district_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>name_english_district</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>lat-lon-city</th>\n",
       "      <th>lat-lon-district</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.0</td>\n",
       "      <td>159.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.0</td>\n",
       "      <td>132.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>96.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>HaiDianBeiJingZhiWuYuan</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.00395 116.20531000000001</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.0</td>\n",
       "      <td>165.3</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>67.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>HaiDianWanLiu</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>39.987313 116.287451</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>162.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>58.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>XiZhiMenBeiDaJie</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>39.954046999999996 116.348991</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124.0</td>\n",
       "      <td>163.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>51.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PM25_Concentration  PM10_Concentration  NO2_Concentration  \\\n",
       "0               138.0               159.4               56.3   \n",
       "1                89.0               132.9               30.5   \n",
       "2                87.0               165.3               78.9   \n",
       "3                91.0               162.2               97.0   \n",
       "4               124.0               163.9               38.7   \n",
       "\n",
       "   CO_Concentration  O3_Concentration  SO2_Concentration  \\\n",
       "0               0.9              50.8               17.2   \n",
       "1               0.8              96.5                7.6   \n",
       "2               0.8              67.4               16.3   \n",
       "3               0.9              58.6               28.6   \n",
       "4               0.9              51.1               17.9   \n",
       "\n",
       "            name_english_x  district_id  station_id name_english_district  \\\n",
       "0        HaiDianBeiBuXinQu        101.0      1001.0             HaiDianQu   \n",
       "1  HaiDianBeiJingZhiWuYuan        101.0      1002.0             HaiDianQu   \n",
       "2            HaiDianWanLiu        101.0      1006.0             HaiDianQu   \n",
       "3         XiZhiMenBeiDaJie        101.0      1008.0             HaiDianQu   \n",
       "4        HaiDianBeiBuXinQu        101.0      1001.0             HaiDianQu   \n",
       "\n",
       "  ...   pressure  humidity  wind_speed  wind_direction           lat-lon-city  \\\n",
       "0 ...     1004.0      56.0        7.92            13.0  116.407394 116.407394   \n",
       "1 ...     1004.0      56.0        7.92            13.0  116.407394 116.407394   \n",
       "2 ...     1004.0      56.0        7.92            13.0  116.407394 116.407394   \n",
       "3 ...     1004.0      56.0        7.92            13.0  116.407394 116.407394   \n",
       "4 ...     1004.0      64.0        7.56            13.0  116.407394 116.407394   \n",
       "\n",
       "                lat-lon-district  year  month day hour  \n",
       "0  40.090678999999994 116.173553  2014      5   1    0  \n",
       "1    40.00395 116.20531000000001  2014      5   1    0  \n",
       "2           39.987313 116.287451  2014      5   1    0  \n",
       "3  39.954046999999996 116.348991  2014      5   1    0  \n",
       "4  40.090678999999994 116.173553  2014      5   1    1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x_numerical = [ 'year', 'month', 'day', 'hour' , 'district_id', 'city_id']\n",
    "train_x_string = ['name_english_x', 'lat-lon-city', 'lat-lon-district',  'name_english_district', ]           \n",
    "train_x_weather = ['weather', 'temperature', 'pressure', 'humidity','wind_speed', 'wind_direction']\n",
    "\n",
    "train_columns = []\n",
    "train_columns.extend(train_x_numerical)\n",
    "train_columns.extend(train_x_weather)\n",
    "\n",
    "train_y_pollution = ['PM25_Concentration', 'PM10_Concentration', 'NO2_Concentration', 'CO_Concentration', 'O3_Concentration', 'SO2_Concentration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>district_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  day  hour  district_id  city_id  weather  temperature  \\\n",
       "567   2014      5    8    23        101.0      1.0      NaN         17.0   \n",
       "568   2014      5    8    23        101.0      1.0      NaN         17.0   \n",
       "569   2014      5    8    23        101.0      1.0      NaN         17.0   \n",
       "570   2014      5    8    23        101.0      1.0      NaN         17.0   \n",
       "767   2014      5   11     1        101.0      1.0      5.0          NaN   \n",
       "768   2014      5   11     1        101.0      1.0      5.0          NaN   \n",
       "769   2014      5   11     1        101.0      1.0      5.0          NaN   \n",
       "770   2014      5   11     1        101.0      1.0      5.0          NaN   \n",
       "2402  2014      5   28     3        101.0      1.0      0.0         18.0   \n",
       "2403  2014      5   28     3        101.0      1.0      0.0         18.0   \n",
       "\n",
       "      pressure  humidity  wind_speed  wind_direction  \n",
       "567     1010.0       0.0        5.76            13.0  \n",
       "568     1010.0       0.0        5.76            13.0  \n",
       "569     1010.0       0.0        5.76            13.0  \n",
       "570     1010.0       0.0        5.76            13.0  \n",
       "767        NaN       NaN         NaN            14.0  \n",
       "768        NaN       NaN         NaN            14.0  \n",
       "769        NaN       NaN         NaN            14.0  \n",
       "770        NaN       NaN         NaN            14.0  \n",
       "2402     998.0       0.0         NaN            23.0  \n",
       "2403     998.0       0.0         NaN            23.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null = final_df[train_columns][final_df[train_columns].isnull().any(axis=1)]\n",
    "df_null.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying simple logistic regression for district predictons \n",
    "\n",
    "1. Type 1 fill NaN with 0 to see how the things are performing \n",
    "2. Remove rows with NaN to see what's the impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138583 784646\n",
      "\n",
      "Coefficients: \n",
      " [[  1.57705524e+01   1.96937980e+00   3.59153798e-01  -3.81221275e-02\n",
      "   -3.00170077e-03   4.02520423e-01   6.06787262e+00  -1.25652492e+00\n",
      "    1.07303575e-02  -1.30123884e-01  -1.24994838e+00   3.37341916e-01]\n",
      " [  3.15273904e+01   3.21920666e+00   8.51417353e-01   1.47536132e-01\n",
      "   -4.37867041e-03   6.82709688e-01   6.17242432e+00  -1.72997770e+00\n",
      "    1.86002295e-02  -4.04073067e-01  -1.27499089e+00   5.78308658e-01]\n",
      " [  1.09534294e+01   1.19429989e+00   1.22986632e-01   8.43228492e-02\n",
      "   -1.72030181e-03   2.00051014e-01   1.61678105e+00  -4.48088910e-01\n",
      "    6.31091042e-03  -1.39613050e-01  -8.58097570e-01   2.82573918e-02]\n",
      " [  2.72671206e-01   3.20252559e-02   3.49020478e-03  -1.99102482e-03\n",
      "   -5.30985106e-05   8.46559081e-03   7.32446013e-02  -2.55451101e-02\n",
      "    1.95059335e-04  -1.51661412e-03  -2.59594793e-02   5.24661209e-03]\n",
      " [ -2.58315336e+01  -3.20506725e+00   1.04866417e-01   1.19412867e+00\n",
      "   -1.72569306e-03   2.37616464e-01  -5.79254474e-02   6.33741426e-01\n",
      "   -1.43654940e-03  -4.34317962e-01   3.11517960e-01  -2.56037908e-02]\n",
      " [  1.09333126e+01   1.15750336e+00   9.30209698e-02   3.21330219e-02\n",
      "   -1.36520093e-03   3.06516413e-01   1.93457237e+00  -8.32910865e-01\n",
      "    1.06256655e-02  -1.52202599e-01  -5.60465543e-01   3.58201478e-01]]\n",
      "\n",
      "\n",
      "Mean squared error for \n",
      "PM25_Concentration    3733.913167\n",
      "PM10_Concentration    8489.671546\n",
      "NO2_Concentration      945.139063\n",
      "CO_Concentration         1.144826\n",
      "O3_Concentration      1983.729213\n",
      "SO2_Concentration     1703.989955\n",
      "dtype: float64\n",
      "\n",
      "Variance score: 0.16\n"
     ]
    }
   ],
   "source": [
    "df = final_df.fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = final_df[~final_df.isnull().any(axis=1)]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using averages to estimate values and rerunning the regressions on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = final_df.groupby(train_x_numerical).mean().reset_index()\n",
    "print (\"With remove NaN's \", len(final_df[~final_df.isnull().any(axis=1)]))\n",
    "print (\"Without removed Nan's \" , len(final_df))\n",
    "print (\"Length of DF with merged \", len(merged_df[~merged_df.isnull().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = merged_df[~merged_df.isnull().any(axis=1)].fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Using a more complicated neural network based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to `[0, 1]` or `[-1, +1]`, or standardize it to have mean `0` and variance `1`. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df = final_df.groupby(train_x_numerical).mean().reset_index()\n",
    "mask = ~merged_df.isnull().any(axis=1)\n",
    "df = merged_df[mask]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train_df[train_columns]\n",
    "Y_train = train_df[train_y_pollution]\n",
    "\n",
    "X_test = train_df[train_columns]\n",
    "Y_test = train_df[train_y_pollution]\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = MLPRegressor()\n",
    "\n",
    "print('Train / Test ', len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "start = timeit.default_timer()\n",
    "regr.fit( X_train , Y_train)\n",
    "stop = timeit.default_timer()\n",
    "train_time = int(stop - start)\n",
    "print('Training finshed in ',train_time , 'seconds')\n",
    "print(\"\\n\\nMean squared error for \")\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))\n",
    "                                                 \n",
    "joblib.dump(regr, 'classifier/MLPRegressor_filtered.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = MLPRegressor(hidden_layer_sizes=(200, ) , max_iter=500)\n",
    "\n",
    "print('Train / Test ', len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "start = timeit.default_timer()\n",
    "regr.fit( X_train , Y_train)\n",
    "stop = timeit.default_timer()\n",
    "train_time = int(stop - start)\n",
    "print('Training finshed in ',train_time , 'seconds')\n",
    "print(\"\\n\\nMean squared error for \")\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))\n",
    "\n",
    "joblib.dump(regr, 'classifier/MLPRegressor_filtered_200_layers.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, using a simple neural network based classifier we can improve on the variance by a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Running for all the data without merging the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = final_df.fillna(-99)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "X_train = train_df[train_columns]\n",
    "Y_train = train_df[train_y_pollution]\n",
    "\n",
    "X_test = train_df[train_columns]\n",
    "Y_test = train_df[train_y_pollution]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=(200, ) , max_iter=500)\n",
    "\n",
    "print(len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "start = timeit.default_timer()\n",
    "regr.fit( X_train , Y_train)\n",
    "stop = timeit.default_timer()\n",
    "train_time = int(stop - start)\n",
    "print('Training finshed in ',train_time , 'seconds')\n",
    "print(\"\\n\\nMean squared error for \")\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))\n",
    "\n",
    "joblib.dump(regr, 'classifier/MLPRegressor_unfiltered_200_layers.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
