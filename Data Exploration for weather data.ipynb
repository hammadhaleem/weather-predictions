{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_airquality = pd.DataFrame.from_csv('data/airquality.csv')\n",
    "df_district = pd.DataFrame.from_csv('data/district.csv')\n",
    "df_meteorology = pd.DataFrame.from_csv('data/meteorology.csv')\n",
    "df_station = pd.DataFrame.from_csv('data/station.csv')\n",
    "df_weatherforecast = pd.DataFrame.from_csv('data/weatherforecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df = df_airquality.join(df_station)\n",
    "final_df = final_df.reset_index()\n",
    "final_df['station_id'] = final_df['\\ufeffstation_id']\n",
    "final_df = final_df.drop('\\ufeffstation_id',1)\n",
    "final_df = final_df.join(df_district, on=['district_id'],rsuffix='_district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_city = pd.DataFrame.from_csv('data/city.csv')\n",
    "df_city = df_city.reset_index()\n",
    "\n",
    "df_city['city_id'] = df_city['\\ufeffcity_id']\n",
    "df_city['latitude_city']= df_city['longitude']\n",
    "df_city['longitude_city']= df_city['longitude']\n",
    "\n",
    "df_city = df_city.drop('latitude',1)\n",
    "df_city = df_city.drop('longitude',1)\n",
    "\n",
    "df_city = df_city.drop('\\ufeffcity_id',1)\n",
    "df_city['city_id'] = df_city.city_id.apply(lambda x : int(x))\n",
    "final_df = pd.merge(final_df, right=df_city,on=['city_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('name_chinese_x',1)\n",
    "final_df = final_df.drop('name_chinese_district',1)\n",
    "final_df = final_df.drop('name_chinese_y',1)\n",
    "final_df = final_df.drop('name_english_y',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology = df_meteorology.reset_index()\n",
    "df_meteorology['id'] = df_meteorology['\\ufeffid']\n",
    "df_meteorology = df_meteorology.drop('\\ufeffid',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology['district_id'] = df_meteorology['id']\n",
    "df_meteorology = df_meteorology.drop('id',1)\n",
    "final_df = pd.merge(final_df, right=df_meteorology,on=['district_id','time'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['latitude_city']  = final_df['latitude_city'].apply(lambda x : str(x))\n",
    "final_df['longitude_city']  = final_df['longitude_city'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['latitude']  = final_df['latitude'].apply(lambda x : str(x))\n",
    "final_df['longitude']  = final_df['longitude'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['lat-lon-city'] = final_df['latitude_city'] + ' ' + final_df['longitude_city']\n",
    "final_df['lat-lon-district'] = final_df['latitude'] + ' ' + final_df['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('latitude_city',1)\n",
    "final_df = final_df.drop('longitude_city',1)\n",
    "\n",
    "final_df = final_df.drop('latitude',1)\n",
    "final_df = final_df.drop('longitude',1)\n",
    "\n",
    "final_df['time'] = final_df.time.apply(lambda x : datetime.datetime.strptime(str(x),'%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['year'] = final_df['time'].apply(lambda x : x.year)\n",
    "final_df['month'] = final_df['time'].apply(lambda x : x.month)\n",
    "final_df['day'] = final_df['time'].apply(lambda x : x.day)\n",
    "final_df['hour'] = final_df['time'].apply(lambda x : x.hour)\n",
    "final_df['minute'] = final_df['time'].apply(lambda x : x.minute)\n",
    "final_df['seconds'] = final_df['time'].apply(lambda x : x.second)\n",
    "\n",
    "final_df = final_df.drop('time',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2891393 entries, 0 to 2891392\n",
      "Data columns (total 26 columns):\n",
      "PM25_Concentration       float64\n",
      "PM10_Concentration       float64\n",
      "NO2_Concentration        float64\n",
      "CO_Concentration         float64\n",
      "O3_Concentration         float64\n",
      "SO2_Concentration        float64\n",
      "name_english_x           object\n",
      "district_id              int64\n",
      "station_id               int64\n",
      "name_english_district    object\n",
      "city_id                  int64\n",
      "cluster_id               int64\n",
      "weather                  float64\n",
      "temperature              float64\n",
      "pressure                 float64\n",
      "humidity                 float64\n",
      "wind_speed               float64\n",
      "wind_direction           float64\n",
      "lat-lon-city             object\n",
      "lat-lon-district         object\n",
      "year                     int64\n",
      "month                    int64\n",
      "day                      int64\n",
      "hour                     int64\n",
      "minute                   int64\n",
      "seconds                  int64\n",
      "dtypes: float64(12), int64(10), object(4)\n",
      "memory usage: 595.6+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it to a temporary data frame \n",
    "# final_df.to_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final_df = pd.DataFrame.from_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PM25_Concentration', 'PM10_Concentration', 'NO2_Concentration',\n",
       "       'CO_Concentration', 'O3_Concentration', 'SO2_Concentration',\n",
       "       'name_english_x', 'district_id', 'station_id', 'name_english_district',\n",
       "       'city_id', 'cluster_id', 'weather', 'temperature', 'pressure',\n",
       "       'humidity', 'wind_speed', 'wind_direction', 'lat-lon-city',\n",
       "       'lat-lon-district', 'year', 'month', 'day', 'hour', 'minute',\n",
       "       'seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "      <th>name_english_x</th>\n",
       "      <th>district_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>name_english_district</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>lat-lon-city</th>\n",
       "      <th>lat-lon-district</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.0</td>\n",
       "      <td>159.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101</td>\n",
       "      <td>1001</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.0</td>\n",
       "      <td>163.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>51.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101</td>\n",
       "      <td>1001</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>7.56</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.0</td>\n",
       "      <td>148.4</td>\n",
       "      <td>55.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101</td>\n",
       "      <td>1001</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.0</td>\n",
       "      <td>145.6</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101</td>\n",
       "      <td>1001</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>6.12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.0</td>\n",
       "      <td>119.3</td>\n",
       "      <td>66.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>HaiDianBeiBuXinQu</td>\n",
       "      <td>101</td>\n",
       "      <td>1001</td>\n",
       "      <td>HaiDianQu</td>\n",
       "      <td>...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.407394 116.407394</td>\n",
       "      <td>40.090678999999994 116.173553</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PM25_Concentration  PM10_Concentration  NO2_Concentration  \\\n",
       "0               138.0               159.4               56.3   \n",
       "1               124.0               163.9               38.7   \n",
       "2               127.0               148.4               55.6   \n",
       "3               129.0               145.6               65.7   \n",
       "4               119.0               119.3               66.9   \n",
       "\n",
       "   CO_Concentration  O3_Concentration  SO2_Concentration     name_english_x  \\\n",
       "0               0.9              50.8               17.2  HaiDianBeiBuXinQu   \n",
       "1               0.9              51.1               17.9  HaiDianBeiBuXinQu   \n",
       "2               1.0              27.2               16.6  HaiDianBeiBuXinQu   \n",
       "3               1.0               9.7               16.7  HaiDianBeiBuXinQu   \n",
       "4               1.0               2.0               16.5  HaiDianBeiBuXinQu   \n",
       "\n",
       "   district_id  station_id name_english_district   ...    wind_speed  \\\n",
       "0          101        1001             HaiDianQu   ...          7.92   \n",
       "1          101        1001             HaiDianQu   ...          7.56   \n",
       "2          101        1001             HaiDianQu   ...          5.76   \n",
       "3          101        1001             HaiDianQu   ...          6.12   \n",
       "4          101        1001             HaiDianQu   ...          4.68   \n",
       "\n",
       "   wind_direction           lat-lon-city               lat-lon-district  year  \\\n",
       "0            13.0  116.407394 116.407394  40.090678999999994 116.173553  2014   \n",
       "1            13.0  116.407394 116.407394  40.090678999999994 116.173553  2014   \n",
       "2            13.0  116.407394 116.407394  40.090678999999994 116.173553  2014   \n",
       "3            13.0  116.407394 116.407394  40.090678999999994 116.173553  2014   \n",
       "4             1.0  116.407394 116.407394  40.090678999999994 116.173553  2014   \n",
       "\n",
       "   month  day  hour minute seconds  \n",
       "0      5    1     0      0       0  \n",
       "1      5    1     1      0       0  \n",
       "2      5    1     2      0       0  \n",
       "3      5    1     3      0       0  \n",
       "4      5    1     4      0       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x_numerical = [ 'year', 'month', 'day', 'hour' , 'minute', 'seconds', 'district_id', 'city_id']\n",
    "train_x_string = ['name_english_x', 'lat-lon-city', 'lat-lon-district',  'name_english_district', ]           \n",
    "train_x_weather = ['weather', 'temperature', 'pressure', 'humidity','wind_speed', 'wind_direction']\n",
    "\n",
    "train_columns = []\n",
    "train_columns.extend(train_x_numerical)\n",
    "train_columns.extend(train_x_weather)\n",
    "\n",
    "train_y_pollution = ['PM25_Concentration', 'PM10_Concentration', 'NO2_Concentration', 'CO_Concentration', 'O3_Concentration', 'SO2_Concentration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>district_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.52</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  day  hour  minute  seconds  district_id  city_id  weather  \\\n",
       "142   2014      5    8    23       0        0          101        1      NaN   \n",
       "192   2014      5   11     1       0        0          101        1      5.0   \n",
       "601   2014      5   28     3       0        0          101        1      0.0   \n",
       "812   2014      6    6    22       0        0          101        1      0.0   \n",
       "813   2014      6    6    23       0        0          101        1      0.0   \n",
       "940   2014      6   12     6       0        0          101        1      0.0   \n",
       "962   2014      6   13     9       0        0          101        1      NaN   \n",
       "975   2014      6   14     5       0        0          101        1      2.0   \n",
       "1054  2014      6   18     3       0        0          101        1      2.0   \n",
       "1170  2014      6   22    23       0        0          101        1      0.0   \n",
       "\n",
       "      temperature  pressure  humidity  wind_speed  wind_direction  \n",
       "142          17.0    1010.0       0.0        5.76            13.0  \n",
       "192           NaN       NaN       NaN         NaN            14.0  \n",
       "601          18.0     998.0       0.0         NaN            23.0  \n",
       "812           NaN       NaN       NaN         NaN             4.0  \n",
       "813           NaN       NaN       NaN         NaN             4.0  \n",
       "940          20.0    1004.0       0.0         NaN             4.0  \n",
       "962          28.0    1004.0       0.0       11.52             9.0  \n",
       "975          19.0    1004.0       0.0         NaN             4.0  \n",
       "1054         19.0    1000.0       0.0         NaN             9.0  \n",
       "1170         19.0    1006.0       0.0         NaN             9.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null = final_df[train_columns][final_df[train_columns].isnull().any(axis=1)]\n",
    "df_null.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying simple logistic regression for district predictons \n",
    "\n",
    "1. Type 1 fill NaN with 0 to see how the things are performing \n",
    "2. Remove rows with NaN to see what's the impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2313114 578279\n",
      "\n",
      "Coefficients: \n",
      " [[  2.05779972e+01   2.67270328e+00   4.35646848e-01  -5.98522880e-02\n",
      "    1.75970349e-13  -4.89386309e-13   1.31129416e+00  -1.31115621e+02\n",
      "    7.43905098e+00  -1.38934958e+00   1.04182082e-02   2.04732378e-01\n",
      "   -1.65157234e+00   4.67988399e-01]\n",
      " [  4.03966348e+01   4.25817170e+00   1.08181157e+00   2.05631154e-01\n",
      "    3.45945494e-13  -8.81961171e-13   2.35485589e+00  -2.35374206e+02\n",
      "    7.03582171e+00  -1.88240478e+00   1.97546622e-02  -5.80280202e-02\n",
      "   -1.41071594e+00   8.98829736e-01]\n",
      " [  1.48436806e+01   1.68720900e+00   1.36391010e-01   1.21168342e-01\n",
      "    4.79616347e-14  -1.21902488e-13   2.51942240e-01  -2.52143551e+01\n",
      "    1.75118578e+00  -3.65168165e-01   8.67108054e-03   2.72088854e-02\n",
      "   -1.12149524e+00   6.32350761e-02]\n",
      " [  3.65915305e-01   4.41737784e-02   3.92115646e-03  -2.79805560e-03\n",
      "    1.47798440e-15  -3.72618603e-15   8.57472545e-03  -8.55724550e-01\n",
      "    8.49144721e-02  -3.14819492e-02   2.62976018e-04   4.91799973e-03\n",
      "   -3.55608832e-02   8.65690476e-03]\n",
      " [ -2.69749874e+01  -3.20302328e+00   7.88223015e-02   1.65966249e+00\n",
      "    1.93178806e-14  -7.06101844e-14   3.80804695e-01  -3.80698558e+01\n",
      "   -3.85087111e-01   1.75177021e+00  -6.44504457e-03  -4.22670485e-01\n",
      "    9.20885914e-01   6.61974852e-02]\n",
      " [  1.33138550e+01   1.45704656e+00   1.06240263e-01   3.28311175e-02\n",
      "    1.67754699e-13  -3.89244192e-13   1.06456643e+00  -1.06327628e+02\n",
      "    2.13987875e+00  -1.08281634e+00   1.44237122e-02  -8.40307683e-02\n",
      "   -7.86489546e-01   5.80901232e-01]]\n",
      "\n",
      "\n",
      "Mean squared error for \n",
      "PM25_Concentration    4092.937971\n",
      "PM10_Concentration    9587.850310\n",
      "NO2_Concentration     1001.567126\n",
      "CO_Concentration         1.280134\n",
      "O3_Concentration      2089.640186\n",
      "SO2_Concentration     2101.809142\n",
      "dtype: float64\n",
      "\n",
      "Variance score: 0.12\n"
     ]
    }
   ],
   "source": [
    "df = final_df.fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620164 155042\n",
      "\n",
      "Coefficients: \n",
      " [[ -3.13376554e+01  -2.58500527e+00   6.63202904e-01   4.02987927e-01\n",
      "   -1.40648604e-12  -1.07358566e-13   1.91095038e+00  -1.90896915e+02\n",
      "    7.25080858e+00  -1.94913598e+00   4.65724866e-01   2.55421956e-01\n",
      "   -1.79113711e+00   6.66858133e-01]\n",
      " [ -3.10822846e+01  -2.72910221e+00   1.62674139e+00   4.92650674e-01\n",
      "   -2.40463205e-12  -1.56430424e-13   3.31310281e+00  -3.30983970e+02\n",
      "    9.35646641e+00  -2.32860740e+00   5.76529249e-01  -1.14895001e-01\n",
      "   -1.50255864e+00   1.04703258e+00]\n",
      " [ -1.90925230e+01  -1.82122876e+00   1.81028320e-01   2.71911608e-01\n",
      "   -2.25541807e-13  -6.53366250e-14   2.97598360e-01  -2.96817591e+01\n",
      "    1.49100973e+00  -7.95645616e-01   2.49818695e-01   5.79366852e-02\n",
      "   -1.28824602e+00   1.16232582e-01]\n",
      " [ -7.03460357e-01  -6.70162560e-02   7.64841136e-03   2.09964272e-03\n",
      "   -1.17362717e-14  -2.73880311e-15   1.61688235e-02  -1.61245038e+00\n",
      "    8.89521322e-02  -4.30711508e-02   8.41557338e-03   3.63080014e-03\n",
      "   -3.69211700e-02   9.01246080e-03]\n",
      " [ -1.21754510e-01  -6.22055686e-01   7.92509177e-02   1.02134593e+00\n",
      "    1.86517468e-14   2.22044605e-16  -2.58578585e-02   2.56200249e+00\n",
      "   -2.59286854e-01   2.28623134e+00  -2.45110646e-01  -5.15978589e-01\n",
      "    7.40925195e-01  -7.60333071e-02]\n",
      " [ -1.46020795e+01  -1.45341509e+00   2.39432682e-01   2.42372850e-01\n",
      "   -1.04299902e-12  -5.05151476e-14   1.42271493e+00  -1.41783915e+02\n",
      "    2.76005709e+00  -1.51709344e+00   2.20405192e-01  -3.35401454e-01\n",
      "   -1.35395411e+00   2.58490287e-01]]\n",
      "\n",
      "\n",
      "Mean squared error for \n",
      "PM25_Concentration     4793.492388\n",
      "PM10_Concentration    11087.125391\n",
      "NO2_Concentration       861.387275\n",
      "CO_Concentration          1.510557\n",
      "O3_Concentration       1401.401938\n",
      "SO2_Concentration      2452.128848\n",
      "dtype: float64\n",
      "\n",
      "Variance score: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = final_df[~final_df.isnull().any(axis=1)]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using averages to estimate values and rerunning the regressions on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With remove NaN's  775206\n",
      "Without removed Nan's  2891393\n",
      "Length of DF with merged  615432\n"
     ]
    }
   ],
   "source": [
    "merged_df = final_df.groupby(train_x_numerical).mean().reset_index()\n",
    "print (\"With remove NaN's \", len(final_df[~final_df.isnull().any(axis=1)]))\n",
    "print (\"Without removed Nan's \" , len(final_df))\n",
    "print (\"Length of DF with merged \", len(merged_df[~merged_df.isnull().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492345 123087\n",
      "\n",
      "Coefficients: \n",
      " [[ -2.34139378e+01  -1.85184286e+00   6.53963899e-01   4.80020942e-01\n",
      "   -4.82613949e-13  -1.59339208e-12   1.96733907e+00  -1.96554040e+02\n",
      "    7.50571573e+00  -1.87752856e+00   4.80545760e-01   3.45271967e-01\n",
      "   -1.92880709e+00   7.03824757e-01]\n",
      " [ -1.33672475e+01  -9.86669253e-01   1.68104048e+00   5.50891830e-01\n",
      "   -8.01358979e-13  -2.77400325e-12   3.38263609e+00  -3.37952616e+02\n",
      "    9.69765753e+00  -2.13282699e+00   6.01215580e-01   5.69409866e-03\n",
      "   -1.63947875e+00   1.09172362e+00]\n",
      " [ -1.44648419e+01  -1.33260111e+00   1.64929650e-01   2.92789278e-01\n",
      "   -6.47329412e-14  -2.48842613e-13   3.28957862e-01  -3.28192155e+01\n",
      "    1.51061451e+00  -7.47665232e-01   2.45050597e-01   7.67386056e-02\n",
      "   -1.28764030e+00   9.54303609e-02]\n",
      " [ -6.71527036e-01  -6.54116439e-02   7.93132408e-03   1.97858819e-03\n",
      "   -2.99955373e-15  -1.11260827e-14   1.49245596e-02  -1.48823744e+00\n",
      "    9.18072224e-02  -4.40008752e-02   8.51965945e-03   3.72326463e-03\n",
      "   -3.92311245e-02   8.84471766e-03]\n",
      " [ -1.36964458e+00  -8.73325475e-01   5.23722585e-02   9.92787167e-01\n",
      "    1.50990331e-14   5.15143483e-14  -5.79465259e-02   5.78413255e+00\n",
      "   -2.35450787e-01   2.32718661e+00  -2.39787329e-01  -4.80942751e-01\n",
      "    8.09532665e-01  -2.34515575e-02]\n",
      " [ -1.49372599e+01  -1.55683099e+00   2.44619867e-01   3.09523204e-01\n",
      "   -3.25850458e-13  -1.13031806e-12   1.41339268e+00  -1.40850818e+02\n",
      "    2.84062592e+00  -1.55508963e+00   2.34452189e-01  -3.37031141e-01\n",
      "   -1.47029902e+00   2.61553095e-01]]\n",
      "\n",
      "\n",
      "Mean squared error for \n",
      "PM25_Concentration     5123.812695\n",
      "PM10_Concentration    11571.649385\n",
      "NO2_Concentration       799.383843\n",
      "CO_Concentration          1.637374\n",
      "O3_Concentration       1297.486525\n",
      "SO2_Concentration      2545.619772\n",
      "dtype: float64\n",
      "\n",
      "Variance score: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = merged_df[~merged_df.isnull().any(axis=1)].fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Using a more complicated neural network based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to `[0, 1]` or `[-1, +1]`, or standardize it to have mean `0` and variance `1`. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492345 123087\n",
      "492345 123087\n",
      "Training neural Network model might take some time\n"
     ]
    }
   ],
   "source": [
    "merged_df = final_df.groupby(train_x_numerical).mean().reset_index()\n",
    "mask = ~merged_df.isnull().any(axis=1)\n",
    "df = merged_df[mask]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train_df[train_columns]\n",
    "Y_train = train_df[train_y_pollution]\n",
    "\n",
    "X_test = train_df[train_columns]\n",
    "Y_test = train_df[train_y_pollution]\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "regr = MLPRegressor()\n",
    "\n",
    "\n",
    "print('Train / Test ', len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "start = timeit.default_timer()\n",
    "regr.fit( X_train , Y_train)\n",
    "stop = timeit.default_timer()\n",
    "train_time = int(stop - start)\n",
    "print('Training finshed in ',train_time , 'seconds')\n",
    "print(\"\\n\\nMean squared error for \")\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, using a simple neural network based classifier we can improve on the variance by a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Running for all the data without merging the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(final_df, test_size = 0.2)\n",
    "\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "X_train = train_df[train_columns]\n",
    "Y_train = train_df[train_y_pollution]\n",
    "\n",
    "X_test = train_df[train_columns]\n",
    "Y_test = train_df[train_y_pollution]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "regr = MLPRegressor()\n",
    "\n",
    "print(len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "start = timeit.default_timer()\n",
    "regr.fit( X_train , Y_train)\n",
    "stop = timeit.default_timer()\n",
    "train_time = int(stop - start)\n",
    "print('Training finshed in ',train_time , 'seconds')\n",
    "print(\"\\n\\nMean squared error for \")\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
