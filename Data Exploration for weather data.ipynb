{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_airquality = pd.DataFrame.from_csv('data/airquality.csv')\n",
    "df_district = pd.DataFrame.from_csv('data/district.csv')\n",
    "df_meteorology = pd.DataFrame.from_csv('data/meteorology.csv')\n",
    "df_station = pd.DataFrame.from_csv('data/station.csv')\n",
    "df_weatherforecast = pd.DataFrame.from_csv('data/weatherforecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df = df_airquality.join(df_station)\n",
    "final_df = final_df.reset_index()\n",
    "final_df['station_id'] = final_df['\\ufeffstation_id']\n",
    "final_df = final_df.drop('\\ufeffstation_id',1)\n",
    "final_df = final_df.join(df_district, on=['district_id'],rsuffix='_district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_city = pd.DataFrame.from_csv('data/city.csv')\n",
    "df_city = df_city.reset_index()\n",
    "\n",
    "df_city['city_id'] = df_city['\\ufeffcity_id']\n",
    "df_city['latitude_city']= df_city['longitude']\n",
    "df_city['longitude_city']= df_city['longitude']\n",
    "\n",
    "df_city = df_city.drop('latitude',1)\n",
    "df_city = df_city.drop('longitude',1)\n",
    "\n",
    "df_city = df_city.drop('\\ufeffcity_id',1)\n",
    "df_city['city_id'] = df_city.city_id.apply(lambda x : int(x))\n",
    "final_df = pd.merge(final_df, right=df_city,on=['city_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('name_chinese_x',1)\n",
    "final_df = final_df.drop('name_chinese_district',1)\n",
    "final_df = final_df.drop('name_chinese_y',1)\n",
    "final_df = final_df.drop('name_english_y',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology = df_meteorology.reset_index()\n",
    "df_meteorology['id'] = df_meteorology['\\ufeffid']\n",
    "df_meteorology = df_meteorology.drop('\\ufeffid',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_meteorology['district_id'] = df_meteorology['id']\n",
    "df_meteorology = df_meteorology.drop('id',1)\n",
    "final_df = pd.merge(final_df, right=df_meteorology,on=['district_id','time'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['latitude_city']  = final_df['latitude_city'].apply(lambda x : str(x))\n",
    "final_df['longitude_city']  = final_df['longitude_city'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['latitude']  = final_df['latitude'].apply(lambda x : str(x))\n",
    "final_df['longitude']  = final_df['longitude'].apply(lambda x : str(x))\n",
    "\n",
    "final_df['lat-lon-city'] = final_df['latitude_city'] + ' ' + final_df['longitude_city']\n",
    "final_df['lat-lon-district'] = final_df['latitude'] + ' ' + final_df['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('latitude_city',1)\n",
    "final_df = final_df.drop('longitude_city',1)\n",
    "\n",
    "final_df = final_df.drop('latitude',1)\n",
    "final_df = final_df.drop('longitude',1)\n",
    "\n",
    "final_df['time'] = final_df.time.apply(lambda x : datetime.datetime.strptime(str(x),'%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['year'] = final_df['time'].apply(lambda x : x.year)\n",
    "final_df['month'] = final_df['time'].apply(lambda x : x.month)\n",
    "final_df['day'] = final_df['time'].apply(lambda x : x.day)\n",
    "final_df['hour'] = final_df['time'].apply(lambda x : x.hour)\n",
    "final_df['minute'] = final_df['time'].apply(lambda x : x.minute)\n",
    "final_df['seconds'] = final_df['time'].apply(lambda x : x.second)\n",
    "\n",
    "final_df = final_df.drop('time',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it to a temporary data frame \n",
    "# final_df.to_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final_df = pd.DataFrame.from_csv('data/final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x_numerical = [ 'year', 'month', 'day', 'hour' , 'minute', 'seconds', 'district_id', 'city_id']\n",
    "train_x_string = ['name_english_x', 'lat-lon-city', 'lat-lon-district',  'name_english_district', ]           \n",
    "train_x_weather = ['weather', 'temperature', 'pressure', 'humidity','wind_speed', 'wind_direction']\n",
    "\n",
    "train_columns = []\n",
    "train_columns.extend(train_x_numerical)\n",
    "train_columns.extend(train_x_weather)\n",
    "\n",
    "train_y_pollution = ['PM25_Concentration', 'PM10_Concentration', 'NO2_Concentration', 'CO_Concentration', 'O3_Concentration', 'SO2_Concentration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_null = final_df[train_columns][final_df[train_columns].isnull().any(axis=1)]\n",
    "df_null.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying simple logistic regression for district predictons \n",
    "\n",
    "1. Type 1 fill NaN with 0 to see how the things are performing \n",
    "2. Remove rows with NaN to see what's the impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = final_df.fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = final_df[~final_df.isnull().any(axis=1)]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using averages to estimate values and rerunning the regressions on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = final_df.groupby(train_x_numerical).mean().reset_index()\n",
    "print (\"With remove NaN's \", len(final_df[~final_df.isnull().any(axis=1)]))\n",
    "print (\"Without removed Nan's \" , len(final_df))\n",
    "print (\"Length of DF with merged \", len(merged_df[~merged_df.isnull().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing entries with NaN values in the regression model\n",
    "# Helped to impove scores\n",
    "df = merged_df[~merged_df.isnull().any(axis=1)].fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_df[train_columns], train_df[train_y_pollution])\n",
    "\n",
    "# The coefficients\n",
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(test_df[train_columns]) - test_df[train_y_pollution]) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(test_df[train_columns], test_df[train_y_pollution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Using a more complicated neural network based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = merged_df[~merged_df.isnull().any(axis=1)].fillna(0.0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "print(len(train_df) , len(test_df))\n",
    "\n",
    "X_train = train_df[train_columns]\n",
    "Y_train = train_df[train_y_pollution]\n",
    "\n",
    "X_test = train_df[train_columns]\n",
    "Y_test = train_df[train_y_pollution]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to `[0, 1]` or `[-1, +1]`, or standardize it to have mean `0` and variance `1`. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(train_df) , len(test_df))\n",
    "print('Training neural Network model might take some time')\n",
    "regr.fit( X_train , Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\nMean squared error for \" )\n",
    "print(np.mean((regr.predict(X_test) - Y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('\\nVariance score: %.2f' % regr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
